{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DINO-DETR Knowledge Distillation on KITTI Dataset\n",
        "\n",
        "This notebook demonstrates the complete pipeline for training a distilled DINO-DETR model on the KITTI dataset.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. **Setup**: Install dependencies and import libraries\n",
        "2. **Data Preparation**: Download and convert KITTI to COCO format\n",
        "3. **Dataset Loading**: Create PyTorch datasets\n",
        "4. **Model Setup**: Load teacher and student models\n",
        "5. **Training**: Train with knowledge distillation\n",
        "6. **Evaluation**: Evaluate with COCO metrics\n",
        "7. **Visualization**: Visualize predictions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")\n",
        "\n",
        "# Mount Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision transformers pycocotools pillow tqdm pyyaml matplotlib opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup working directory\n",
        "import os\n",
        "if IN_COLAB:\n",
        "    # Clone repository if needed\n",
        "    if not os.path.exists('object-detection'):\n",
        "        !git clone https://github.com/your-repo/object-detection.git\n",
        "        %cd object-detection\n",
        "else:\n",
        "    # Navigate to repository root if in notebooks folder\n",
        "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "        os.chdir('..')\n",
        "print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import project modules\n",
        "from src.datasets import build_kitti_coco_dataset, collate_fn\n",
        "from src.models import build_teacher_student_models\n",
        "from src.distillation import DistillationLoss, DistillationTrainer\n",
        "from src.utils import get_device, seed_all\n",
        "\n",
        "print(\"‚úì All imports successful\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {get_device()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    # Paths\n",
        "    'kitti_root': './kitti_data/training',\n",
        "    'data_root': './kitti_coco',\n",
        "    'output_dir': './output/distillation_notebook',\n",
        "    \n",
        "    # Data\n",
        "    'num_labels': 4,  # car, person, bicycle + background\n",
        "    'train_split': 0.8,\n",
        "    'max_samples': 200,  # Use subset for faster training\n",
        "    \n",
        "    # Models\n",
        "    'teacher_model': 'IDEA-Research/dino-detr-resnet-50',\n",
        "    'student_model': 'IDEA-Research/dino-detr-resnet-50',\n",
        "    \n",
        "    # Training\n",
        "    'batch_size': 2,\n",
        "    'num_workers': 2,\n",
        "    'epochs': 3,\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 1e-4,\n",
        "    \n",
        "    # Distillation\n",
        "    'temperature': 2.0,\n",
        "    'alpha': 0.5,\n",
        "    \n",
        "    # Other\n",
        "    'seed': 42,\n",
        "    'device': None,  # auto-detect\n",
        "}\n",
        "\n",
        "# Set random seed\n",
        "seed_all(CONFIG['seed'])\n",
        "\n",
        "# Get device\n",
        "device = get_device(CONFIG['device'])\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create output directory\n",
        "Path(CONFIG['output_dir']).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nüìã Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download KITTI if not exists\n",
        "if not Path(CONFIG['kitti_root']).exists():\n",
        "    print(\"Downloading KITTI dataset...\")\n",
        "    !python scripts/download_kitti.py --output-dir ./kitti_data\n",
        "else:\n",
        "    print(\"‚úì KITTI dataset already exists\")\n",
        "\n",
        "# Convert to COCO format if not exists\n",
        "if not Path(CONFIG['data_root']).exists():\n",
        "    print(\"\\nConverting to COCO format...\")\n",
        "    !python scripts/prepare_kitti_coco.py \\\n",
        "        --kitti-root {CONFIG['kitti_root']} \\\n",
        "        --output-dir {CONFIG['data_root']} \\\n",
        "        --train-split {CONFIG['train_split']} \\\n",
        "        --max-samples {CONFIG['max_samples']}\n",
        "else:\n",
        "    print(\"‚úì COCO format dataset already exists\")\n",
        "\n",
        "print(\"\\n‚úì Dataset ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Datasets and Create Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading datasets...\")\n",
        "\n",
        "train_dataset = build_kitti_coco_dataset(\n",
        "    split='train',\n",
        "    data_root=CONFIG['data_root'],\n",
        "    transforms=None,\n",
        ")\n",
        "\n",
        "val_dataset = build_kitti_coco_dataset(\n",
        "    split='val',\n",
        "    data_root=CONFIG['data_root'],\n",
        "    transforms=None,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=CONFIG['num_workers'],\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=CONFIG['num_workers'],\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "print(f\"‚úì Train dataset: {len(train_dataset)} samples ({len(train_loader)} batches)\")\n",
        "print(f\"‚úì Val dataset: {len(val_dataset)} samples ({len(val_loader)} batches)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load Teacher and Student Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading models...\")\n",
        "print(f\"Teacher: {CONFIG['teacher_model']}\")\n",
        "print(f\"Student: {CONFIG['student_model']}\")\n",
        "\n",
        "teacher_model, student_model, image_processor = build_teacher_student_models(\n",
        "    teacher_model_name=CONFIG['teacher_model'],\n",
        "    student_model_name=CONFIG['student_model'],\n",
        "    num_labels=CONFIG['num_labels'],\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "# Count parameters\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "student_trainable = sum(p.numel() for p in student_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\n‚úì Models loaded\")\n",
        "print(f\"  Teacher parameters: {teacher_params:,}\")\n",
        "print(f\"  Student parameters: {student_params:,} ({student_trainable:,} trainable)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Setup Training with Distillation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    student_model.parameters(),\n",
        "    lr=CONFIG['learning_rate'],\n",
        "    weight_decay=CONFIG['weight_decay'],\n",
        ")\n",
        "\n",
        "# Setup distillation loss\n",
        "distillation_loss = DistillationLoss(\n",
        "    temperature=CONFIG['temperature'],\n",
        "    alpha=CONFIG['alpha'],\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = DistillationTrainer(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=student_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    distillation_loss=distillation_loss,\n",
        "    device=device,\n",
        "    output_dir=CONFIG['output_dir'],\n",
        ")\n",
        "\n",
        "print(\"‚úì Training setup complete\")\n",
        "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
        "print(f\"  Temperature: {CONFIG['temperature']}\")\n",
        "print(f\"  Alpha: {CONFIG['alpha']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train Model\n",
        "\n",
        "Train the student model with knowledge distillation from the teacher.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Starting training for {CONFIG['epochs']} epochs...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Train\n",
        "trainer.train(num_epochs=CONFIG['epochs'], save_every=1)\n",
        "\n",
        "print(\"\\n‚úì Training complete!\")\n",
        "print(f\"Checkpoints saved to: {CONFIG['output_dir']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Evaluate Model\n",
        "\n",
        "Evaluate the trained student model on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    \\\"\\\"\\\"Evaluate model on validation set.\\\"\\\"\\\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    \n",
        "    for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "        images = [img.to(device) for img in images]\n",
        "        outputs = model(images)\n",
        "        \n",
        "        for output, target in zip(outputs, targets):\n",
        "            image_id = target['image_id'].item()\n",
        "            logits = output['logits']\n",
        "            boxes = output['pred_boxes']\n",
        "            \n",
        "            scores = logits.softmax(-1)[:, :-1].max(-1)\n",
        "            labels = scores.indices\n",
        "            scores = scores.values\n",
        "            \n",
        "            keep = scores > 0.3\n",
        "            for box, score, label in zip(boxes[keep], scores[keep], labels[keep]):\n",
        "                predictions.append({\n",
        "                    'image_id': image_id,\n",
        "                    'category_id': int(label.item()) + 1,\n",
        "                    'bbox': box.cpu().tolist(),\n",
        "                    'score': float(score.item()),\n",
        "                })\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "print(\"Evaluating on validation set...\")\n",
        "predictions = evaluate_model(student_model, val_loader, device)\n",
        "print(f\"‚úì Generated {len(predictions)} predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run COCO evaluation\n",
        "if len(predictions) > 0:\n",
        "    print(\"\\nRunning COCO evaluation...\")\n",
        "    ann_file = Path(CONFIG['data_root']) / 'annotations' / 'instances_val.json'\n",
        "    \n",
        "    coco_gt = COCO(str(ann_file))\n",
        "    coco_dt = coco_gt.loadRes(predictions)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No predictions to evaluate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualize Predictions\n",
        "\n",
        "Visualize sample predictions from the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_predictions(model, dataset, device, num_samples=3):\n",
        "    \\\"\\\"\\\"Visualize predictions on random samples.\\\"\\\"\\\"\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
        "    if num_samples == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    indices = random.sample(range(len(dataset)), num_samples)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, ax in zip(indices, axes):\n",
        "            image, target = dataset[idx]\n",
        "            image_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(image_tensor)[0]\n",
        "            \n",
        "            logits = outputs['logits']\n",
        "            boxes = outputs['pred_boxes']\n",
        "            scores = logits.softmax(-1)[:, :-1].max(-1)\n",
        "            labels = scores.indices\n",
        "            scores = scores.values\n",
        "            keep = scores > 0.5\n",
        "            \n",
        "            img_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "            img_np = (img_np * 255).astype(np.uint8)\n",
        "            h, w = img_np.shape[:2]\n",
        "            \n",
        "            for box, score in zip(boxes[keep], scores[keep]):\n",
        "                cx, cy, bw, bh = box.cpu().numpy()\n",
        "                x1 = int((cx - bw/2) * w)\n",
        "                y1 = int((cy - bh/2) * h)\n",
        "                x2 = int((cx + bw/2) * w)\n",
        "                y2 = int((cy + bh/2) * h)\n",
        "                cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(img_np, f\"{score.item():.2f}\", (x1, y1-5),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "            \n",
        "            ax.imshow(img_np)\n",
        "            ax.set_title(f\"Predictions (n={keep.sum()})\")\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(student_model, val_dataset, device, num_samples=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary\n",
        "\n",
        "Knowledge distillation training completed successfully!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üéâ KNOWLEDGE DISTILLATION PIPELINE COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚úì Dataset prepared and loaded\")\n",
        "print(\"‚úì Teacher and student models configured\")\n",
        "print(\"‚úì Training completed with distillation\")\n",
        "print(\"‚úì Model evaluated with COCO metrics\")\n",
        "print(\"‚úì Predictions visualized\")\n",
        "print(f\"\\nüìÅ Output directory: {CONFIG['output_dir']}\")\n",
        "print(\"   - best.pth: Best model checkpoint\")\n",
        "print(\"   - epoch_*.pth: Epoch checkpoints\")\n",
        "print(\"\\nüöÄ Next Steps:\")\n",
        "print(\"   1. Train for more epochs\")\n",
        "print(\"   2. Tune hyperparameters\")\n",
        "print(\"   3. Try different model pairs\")\n",
        "print(\"   4. Deploy the model\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
